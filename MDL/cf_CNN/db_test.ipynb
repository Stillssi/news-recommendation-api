{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/x8smbq7d6l1g33fxnfy1j4b80000gn/T/ipykernel_8149/3598819719.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df=pd.read_sql(SQL, db)\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "host_name = 'localhost'\n",
    "host_port = 3306\n",
    "username='root'\n",
    "password=''\n",
    "database_name='news_team_4'\n",
    "\n",
    "db = pymysql.connect(\n",
    "    host=host_name,\n",
    "    port=host_port,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    db=database_name,\n",
    "    charset='utf8'\n",
    ")\n",
    "\n",
    "SQL='SELECT * FROM tb_news_team_4'\n",
    "df=pd.read_sql(SQL, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201941, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MainCategory SubCategory\n",
      "169173           사회       식품/의료\n",
      "       MainCategory SubCategory\n",
      "879769           세계      아시아/호주\n",
      "       MainCategory SubCategory\n",
      "910410           세계       세계 일반\n",
      "       MainCategory SubCategory\n",
      "257771           정치       국회/정당\n",
      "       MainCategory SubCategory\n",
      "893579           세계       세계 일반\n"
     ]
    }
   ],
   "source": [
    "print(df[df['ID']==169174][['MainCategory','SubCategory']])\n",
    "print(df[df['ID']==1013437][['MainCategory','SubCategory']])\n",
    "print(df[df['ID']==1044078][['MainCategory','SubCategory']])\n",
    "print(df[df['ID']==391439][['MainCategory','SubCategory']])\n",
    "print(df[df['ID']==1027247][['MainCategory','SubCategory']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505467    尹 대통령 지지율, 16%까지 곤두박질 ‘주요국 꼴찌’…非지지 최고 81% [나우,어스]\n",
      "Name: Title, dtype: object\n",
      "540642    팔순 맞는 바이든…중간선거 선방에 '대선은 여든부터' 통할까\n",
      "Name: Title, dtype: object\n",
      "533582    공화당에 하원 내주고도 바이든 \"민주주의 지켜냈다\"\n",
      "Name: Title, dtype: object\n",
      "489488    中 상하이 봉쇄 때보다 심각...시위·폭동까지\n",
      "Name: Title, dtype: object\n",
      "521363    '헤르손 결전' 임박...서방, '전차와 호크' 첫 지원\n",
      "Name: Title, dtype: object\n",
      "484535    대만 지방선거서 여당 참패…차이잉원 총통 당 주석직 사퇴\n",
      "Name: Title, dtype: object\n",
      "455126    “이걸로 삼성 크게 위협?” 중국 여성 손에 접는폰 ‘정체’ 알고보니\n",
      "Name: Title, dtype: object\n",
      "---------\n",
      "495644    이란 대표팀, 월드컵서 국가 제창 거부로 '히잡 시위' 연대\n",
      "Name: Title, dtype: object\n",
      "495731    \"한미일 외교차관, 北ICBM 발사 강력규탄·3자협력 중요성 확인\"\n",
      "Name: Title, dtype: object\n",
      "496155    방역 고삐 죄는 중국‥곳곳서 도심 봉쇄\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[df['ID']==639135]['Title'])\n",
    "print(df[df['ID']==674310]['Title'])\n",
    "print(df[df['ID']==667250]['Title'])\n",
    "print(df[df['ID']==623156]['Title'])\n",
    "print(df[df['ID']==655031]['Title'])\n",
    "print(df[df['ID']==618203]['Title'])\n",
    "print(df[df['ID']==588794]['Title'])\n",
    "print('---------')\n",
    "print(df[df['ID']==629312]['Title'])\n",
    "print(df[df['ID']==629399]['Title'])\n",
    "print(df[df['ID']==629823]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choibowon/opt/anaconda3/envs/project1/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # raw dataset\n",
    "from surprise import SVD, accuracy # SVD model, 평가\n",
    "from surprise import Reader, Dataset # SVD model의 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm  # 반복문 진행상황 보기\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class MonitorCallback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.last = time.time()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print('epoch ends {}: {}'.format(self.epoch, time.time() - self.last))\n",
    "        self.epoch += 1\n",
    "        self.last = time.time()\n",
    "\n",
    "\n",
    "# to see all data\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 450)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "\n",
    "columns = ['DomainID', 'MainCategory', 'SubCategory', 'WritedAt', 'Title', 'Content', 'URL', 'PhotoURL', 'Writer',\n",
    "           'Press', 'Stickers', 'UserID', 'Comment_content', 'Comment_WritedAt', 'UserName']\n",
    "\n",
    "# df_news_foreign_dataset = pd.read_csv('news_4.csv')\n",
    "\n",
    "def preprocessing_korean(data):\n",
    "    fi_da = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ.*\\\\s]\", '', data).replace('\\xa0', '')\n",
    "    fi_da = fi_da.replace(\"..\", '').split('.')\n",
    "    return fi_da\n",
    "\n",
    "def make_doc2vec_data(df: pd.DataFrame):\n",
    "    df.dropna(axis='index', inplace=True)\n",
    "    tagged_corpus_list = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        mecab = Mecab()\n",
    "        text = df['Content']\n",
    "        tag = row['Title']\n",
    "        tagged_corpus_list.append(TaggedDocument(tags=[tag], words=mecab.morphs(text)))\n",
    "        if idx > 1000:\n",
    "            break\n",
    "    return tagged_corpus_list\n",
    "\n",
    "tagged_corpus_list = make_doc2vec_data(df)\n",
    "model = Doc2Vec(vector_size=100, alpha=0.025, min_alpha=0.01, workers=6, window=2, callbacks=[MonitorCallback()])\n",
    "model.build_vocab(tagged_corpus_list)\n",
    "model.train(tagged_corpus_list, total_examples=model.corpus_count, epochs=50)\n",
    "\n",
    "def cos_simimlarity(first_docu, second_docu):\n",
    "    return dot(first_docu, second_docu) / (\n",
    "            norm(first_docu) * norm(second_docu))\n",
    "\n",
    "df.dropna(subset=['Content'], inplace=True)\n",
    "mdoel_size = len(loaded_model.dv)\n",
    "\n",
    "similarity_scores = []\n",
    "similarity_scores_list = []\n",
    "for idx, content_first in enumerate(tqdm(loaded_model.dv)):\n",
    "    for idx_second in range(0, mdoel_size - 1):\n",
    "        try:\n",
    "            # similarity_scores.append(cos_simimlarity(content_first, loaded_model.dv[idx_second]))\n",
    "            cosine_result = cosine_similarity([loaded_model.dv[idx].T], [loaded_model.dv[idx_second]])\n",
    "            similarity_scores.append(*cosine_result)\n",
    "            # print(\"cosine_result : \" , idx, idx_second, *cosine_result)\n",
    "        except Exception as e:\n",
    "            print(\"Exception : \", idx, \":\", idx_second, \":\", e)\n",
    "    similarity_scores_list.append(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/x8smbq7d6l1g33fxnfy1j4b80000gn/T/ipykernel_16962/3335904482.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_df['Content'] = content['Content'].apply(lambda x : ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "\n",
    "def preprocessing(data):\n",
    "    text=re.sub(\"[①②③④⑤⑥⑦⑧⑨⑩○●〈〉]\",'',data).replace('\\xa0','')\n",
    "    return text\n",
    "\n",
    "def mecab_morphs(data):\n",
    "    pos_list = {'NNG', 'VA', 'VAX', 'MAG', 'NNP', 'VV+EC','VV+ETM'}\n",
    "    mecab = Mecab()\n",
    "    data_token = mecab.morphs(data)\n",
    "    f = open('./stopwords-ko.txt', 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    stopwords_list= []\n",
    "    for l in lines:\n",
    "        l = l.replace('\\n','')\n",
    "        stopwords_list.append(l)\n",
    "    \n",
    "    result = []\n",
    "    for token in data_token:\n",
    "        if token not in stopwords_list:\n",
    "            result.append(token)\n",
    "    \n",
    "    token_result = ''.join(result)\n",
    "    pos_token = mecab.pos(token_result)\n",
    "    pos_result = []\n",
    "    for p in pos_token:\n",
    "        if p[1] in pos_list:\n",
    "            pos_result.append(p[0])\n",
    "    pos_result = list(set(pos_result))\n",
    "    \n",
    "    return pos_result\n",
    "\n",
    "def article_preprocessing(news_df): \n",
    "    '''\n",
    "    데이터 프레임 각 기사 내용 전처리\n",
    "    '''\n",
    "    c= news_df['Content']\n",
    "    content = pd.DataFrame(data=c, columns=['Content'])\n",
    "    content['Content'].apply(lambda x: str(x))\n",
    "    content['Content'] = content['Content'].apply(lambda x : preprocessing(x))\n",
    "    content['Content'] = content['Content'].apply(lambda x : mecab_morphs(x))\n",
    "    news_df['Content'] = content['Content'].apply(lambda x : ' '.join(x))\n",
    "\n",
    "    return news_df\n",
    "\n",
    "# news_df = pd.read_csv('./Article_news.csv') #뉴스 기사 있는 csv파일\n",
    "result_df = article_preprocessing(df[600972:]) #원래 데이터 프레임 + 전처리된 내용\n",
    "result_df.to_csv('./news_prep2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451225     먹통 재발 추구 방지 대책 진행 원인 남궁훈 데이터 바라 발전 중요 이렇게 다시 언...\n",
       "455695     기능 평가 뒤 한계 충실 브랜드 발광 칼 쉽 흑백 난이도 호평 주목 샤프 대용량 과...\n",
       "432293     자금 큰손 우량 쉽 유예 높 회사채 대비 줄 보험 기금 사채 유동 치우 수요 당국 ...\n",
       "692660     기능 앞서 오후 공공 망 개시 정차 대책 재난 경계 추진 단속 지역 교통부 반 임무...\n",
       "270408     앞서 평가 뒤 공백 인물 예측 깊 관악 갖 나타낼 정심 장엄 준비 전국 기본 총선 ...\n",
       "                                 ...                        \n",
       "275075     드린 고차방정식 언론 느끼 저항감 존중 드리 설치 종교 기후 구결 낙태 환경 혼문 ...\n",
       "195078     연안 울진 확보 독 생물 조종 높 다양 확대 보전 전국 중요 설치 기후 진봉 지역 ...\n",
       "1044987    느 평가 국제 음일 심기 방지 중립 법인 노인 체계 고강 공동체 보전 청렴 기구 전...\n",
       "941084     종합 건달 국회 차차 오후 소속 행정 지난달 방청 초동 없 관계 상황실 자료 그대로...\n",
       "659665     건립 축하 하반기 원인 세대 임신 채택 구조 전국 기금 발전 기본 최대한 정도 지역...\n",
       "Name: Content, Length: 5910, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['Content'].iloc[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/x8smbq7d6l1g33fxnfy1j4b80000gn/T/ipykernel_5500/1927856447.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_1=pd.read_csv('news_prep1.csv')\n",
      "/var/folders/xr/x8smbq7d6l1g33fxnfy1j4b80000gn/T/ipykernel_5500/1927856447.py:4: DtypeWarning: Columns (8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2=pd.read_csv('news_prep2.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1201941, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_1=pd.read_csv('news_prep1.csv')\n",
    "df_2=pd.read_csv('news_prep2.csv')\n",
    "\n",
    "result_df = pd.concat([df_1, df_2])\n",
    "result_df['CosSimilarity']=0\n",
    "\n",
    "result_df.shape\n",
    "\n",
    "# result_df.to_csv(\"news_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"news_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201941, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/x8smbq7d6l1g33fxnfy1j4b80000gn/T/ipykernel_5500/2799023512.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df=pd.read_sql(SQL, db)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1201941, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL='SELECT * FROM tb_news_team_4'\n",
    "df=pd.read_sql(SQL, db)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm  # 반복문 진행상황 보기\n",
    "\n",
    "# to see all data\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 450)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "\n",
    "columns = ['DomainID', 'MainCategory', 'SubCategory', 'WritedAt', 'Title', 'Content', 'URL', 'PhotoURL', 'Writer',\n",
    "           'Press', 'Stickers', 'UserID', 'Comment_content', 'Comment_WritedAt', 'UserName']\n",
    "\n",
    "df_news_foreign_dataset = df\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "df_news_foreign_dataset.dropna(axis='index', inplace=True)\n",
    "\n",
    "tagged_corpus_list = []\n",
    "for idx, row in tqdm(df_news_foreign_dataset.iterrows(), total=len(df_news_foreign_dataset)):\n",
    "    text = row['Content']\n",
    "    tag = row['Title']\n",
    "    tagged_corpus_list.append(TaggedDocument(tags=[tag], words=mecab.morphs(text)))\n",
    "    if idx > 1000:\n",
    "        break\n",
    "    \n",
    "model = Doc2Vec(vector_size=100, alpha=0.025, min_alpha=0.01, workers=6, window=2)\n",
    "model.build_vocab(tagged_corpus_list)\n",
    "model.train(tagged_corpus_list, total_examples=model.corpus_count, epochs=50)\n",
    "# model.infer_vector(df_news_foreign_dataset['Content'])\n",
    "print(model.dv.most_similar(\"싸이에 버림받은 코인 '싸이클럽' 결국 국내 상폐\", topn=20))\n",
    "print()\n",
    "print(model.dv.most_similar(\"싸이에 버림받은 코인 '싸이클럽' 결국 국내 상폐\"))\n",
    "print()\n",
    "print(model.dv.most_similar(\"니콘이미징코리아, 고진영 프로와 6년 연속 쿨샷 전속모델 계약\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.to_csv(\"news_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comm_df=pd.read_csv('News_4_Comment.csv')\n",
    "\n",
    "# comm_df['CosSimilarity']= np.nan\n",
    "\n",
    "# comm_df.to_csv(\"comm_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('project1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  4 2022, 08:45:18) [Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "101b816fe1d0b90b733dc5a58a81038627d273f97be30c1d87794f54cdbf127f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
